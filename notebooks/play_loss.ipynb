{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff8571a3-084c-4994-869e-aaf60dfe5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.losses import KLDivergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc654f4e-d437-4648-8282-3b462718c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kW = np.random.randn(256, 10)\n",
    "y = np.random.randn(32, 10)\n",
    "\n",
    "kW_pt = torch.from_numpy(kW)\n",
    "y_pt = torch.from_numpy(y)\n",
    "\n",
    "\n",
    "j = tf.argmax(y, axis=1)\n",
    "j_pt = torch.argmax(y_pt, dim=1)\n",
    "\n",
    "y_j = tf.reduce_max(y, axis=1, keepdims=True)\n",
    "y_j_pt = torch.max(y_pt, dim=1, keepdim=True)[0]\n",
    "\n",
    "where_not_j = tf.not_equal(y, y_j)\n",
    "where_not_j_pt = torch.not_equal(y_pt, y_j_pt)\n",
    "\n",
    "# Get the weight column of the predicted class.\n",
    "kW_j = tf.gather(tf.transpose(kW), j)\n",
    "kW_j_pt = kW_pt.T[j_pt]\n",
    "\n",
    "# Get weights that predict the value y_j - y_i for all i != j.\n",
    "kW_ij = kW_j[:,:,None] - kW[None]\n",
    "kW_ij_pt = kW_j_pt[:,:,None] - kW_pt[None]\n",
    "\n",
    "# We do this instead of `tf.linalg.norm(W_d)` because of an apparent bug\n",
    "# in `tf.linalg.norm` that leads to NaN values.\n",
    "K_ij = tf.sqrt(tf.reduce_sum(kW_ij * kW_ij, axis=1))\n",
    "K_ij_pt = torch.sqrt(torch.sum(kW_ij_pt * kW_ij_pt, dim=1))\n",
    "\n",
    "lip_con = tf.where(\n",
    "    tf.equal(y, y_j), \n",
    "    tf.zeros_like(K_ij) - 1., \n",
    "    K_ij)\n",
    "lip_con_pt = torch.where(torch.eq(y_pt, y_j_pt), torch.zeros_like(K_ij_pt) - 1., K_ij_pt)\n",
    "\n",
    "y_bot_i = y + 1.58 * K_ij\n",
    "y_bot_i_pt = y_pt + 1.58 * K_ij_pt\n",
    "\n",
    "# `y_bot_i` will be zero at the position of class j. However, we don't \n",
    "# want to consider this class, so we replace the zero with negative\n",
    "# infinity so that when we find the maximum component for `y_bot_i` we \n",
    "# don't get zero as a result of all of the components we care aobut \n",
    "# being negative.\n",
    "y_bot_i = tf.where(\n",
    "    tf.equal(y, y_j), \n",
    "    -np.infty + tf.zeros_like(y_bot_i), \n",
    "    y_bot_i)\n",
    "y_bot_i_pt = torch.where(torch.eq(y_pt, y_j_pt), -np.infty + torch.zeros_like(y_bot_i_pt), y_bot_i_pt)\n",
    "\n",
    "\n",
    "y_bot = tf.reduce_max(y_bot_i, axis=1, keepdims=True)\n",
    "y_bot_pt = torch.max(y_bot_i_pt, dim=1, keepdim=True)[0]\n",
    "\n",
    "y_true = torch.randn(32, 10).argmax(dim=1).numpy()\n",
    "\n",
    "y_pred = tf.concat([y, y_bot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3a76a212-4f0c-4a93-a6f4-63332d04903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scc = SparseCategoricalCrossentropy(from_logits=True)\n",
    "cc = CategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3af5ba49-1251-484c-830f-2873b69b808a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 1]), torch.Size([32, 1]), (32,))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_bot.shape, y_bot_pt.shape, y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1be3dbc9-02b6-4d83-8350-49300e762fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 11])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([y, y_bot], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "201532a1-a953-474b-97f4-82529a4c70cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_extra_column(y):\n",
    "    return np.concatenate((y, np.zeros((y.shape[0], 1))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "768c5d77-a252-4184-ae74-effebe67e205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 11)\n",
      "(32, 11)\n",
      "(32, 11)\n",
      "tf.Tensor(5.273375034332275, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# y_true = tf.concat((y_true, tf.zeros((tf.shape(y_true)[0], 1))), axis=1)\n",
    "\n",
    "# Encourage predicting the correct class, even non-robustly.\n",
    "standard_loss = scc(y_true, y_pred[:, :-1])\n",
    "\n",
    "# Encourage predicting robustly, even incorrectly. We take the robust\n",
    "# loss but using the model's prediction as the ground truth.\n",
    "print (y_pred.shape)\n",
    "y_pred_soft = tf.nn.softmax(y_pred)\n",
    "print (y_pred_soft.shape)\n",
    "\n",
    "new_ground_truth = add_extra_column(tf.nn.softmax(y_pred[:, :-1]))\n",
    "print (new_ground_truth.shape)\n",
    "\n",
    "robust_loss = cc(\n",
    "    new_ground_truth, y_pred_soft / 1)\n",
    "# Combine the standard and robust terms.\n",
    "print (standard_loss + 1 * robust_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c10922a7-9563-43e6-849d-0150d17afdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((y_pt.shape[0], 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "599e4a7f-531a-4dba-ba25-5b3179164903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 11])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([y_pt, torch.zeros((y_pt.shape[0], 1))], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7155fa2-9ade-4674-9d09-53f5048aa8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b14f275-8213-4160-8d03-1a19f6e85843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8285],\n",
       "        [-1.0093],\n",
       "        [-0.8830],\n",
       "        [-1.8680],\n",
       "        [ 1.3652],\n",
       "        [-1.8765],\n",
       "        [ 0.4063],\n",
       "        [-0.9555],\n",
       "        [-1.4613],\n",
       "        [-1.3024]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(tf.random.truncated_normal((10, 1)).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3677a116-0a8e-49d2-93b9-aa14d8010359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9695],\n",
       "        [0.7198],\n",
       "        [0.6941],\n",
       "        [0.7773],\n",
       "        [0.8283],\n",
       "        [0.3203],\n",
       "        [0.5991],\n",
       "        [0.8982],\n",
       "        [0.3592],\n",
       "        [0.1972]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(10, 1) * (1 - np.exp(-2)) + np.exp(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83895d54-4f85-4d6b-8cfc-094436cecee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8261fb83-3a81-4959-8aca-21e86eeba362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
