{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6c31dd1-81dc-4a82-a7c0-f6e10b2bda90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/versag/anaconda3/envs/liptrf/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "import math\n",
=======
    "import math \n",
>>>>>>> 9f246edb5948743bdc75fc1efea83f707fcd5e56
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import torch \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "80366a3e-5238-45a4-880b-42345d10db71",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "def toeplitz_2dconv(inp, w, stride, padding='same'):\n",
    "    \"\"\"\n",
    "    FCN form of a MIMO convolutional layer\n",
    "     h: DxCxL kernel matrix \n",
    "     with D: number of output channels\n",
    "          C: number of input channels\n",
    "          L: kernel 2D dimensions\n",
    "     x: CxT(1)xT(2)xK input\n",
    "     with T: image size\n",
    "          K: number of samples\n",
    "     stride: stride\n",
    "     padding: 'full' for generating outputs of length T' = T-L+1\n",
    "          otherwise default is same length T' = T\n",
    "     Y: D x (K T'(1) T'(2)/s^2) output matrix\n",
    "     X: (C L(1) L(2)) x (K T'(1) T'(2)/s^2) input matrix\n",
    "     W: D x (C L(1) L(2)) matrix \n",
    "    \"\"\"\n",
    "    batch_size, channels, height, width = inp.shape\n",
    "    out_size, _, k_height, k_width = w.shape\n",
    "\n",
    "    W = [];\n",
    "    X = [];\n",
    "\n",
    "    if padding == 'same':\n",
    "        L1 = math.floor((L-1)/2)\n",
    "        L2 = math.ceil((L-1)/2)\n",
    "    elif paddin == 'full':\n",
    "        L1 = [0 0]\n",
    "        L2 = [0 0]\n",
    "    else\n",
    "        print ('padding undefined')\n",
    "\n",
    "\n",
    "    for c in range(channels):\n",
    "        W = [W reshape(h(:,c,:,:),[D L(1)*L(2)])]\n",
    "        XX = []\n",
    "        for k = 1:K\n",
    "             for t2 = L(2)-L1(2):s:T(2)+L2(2)\n",
    "                XXT = []\n",
    "                for tt2 = t2:-1:t2-L(2)+1\n",
    "                    if tt2 > 0 & tt2 <= T(2)\n",
    "                        XXT = [XXT;toeplitz([x(c,L(1)-L1(1):-1:1,tt2,k) zeros(1,L1(1))],[x(c,L(1)-L1(1):end,tt2,k) zeros(1,L2(1))])]\n",
    "                    else\n",
    "                        XXT = [XXT;zeros(L(1),T(1))]\n",
    "                XX = [XX XXT(:,1:s:end)]\n",
    "         \n",
    "        X = [X;XX]\n",
    "    \n",
    "    Y = W*X"
=======
    "def toeplitz_conv2d(inp, w, stride, padding='same'):\n",
    "    \"\"\"\n",
    "    %[Y,X,W]  = conv_lay_mat(x,h,s) : FCN form of a MIMO convolutional layer\n",
    "    % h: DxCxL kernel matrix \n",
    "    % with D: number of output channels\n",
    "    %      C: number of input channels\n",
    "    %      L: kernel 2D dimensions\n",
    "    % x: CxT(1)xT(2)xK input\n",
    "    % with T: image size\n",
    "    %      K: number of samples\n",
    "    % s: stride\n",
    "    % pad: 'full' for generating outputs of length T' = T-L+1\n",
    "    %      otherwise default is same length T' = T\n",
    "    % Y: D x (K T'(1) T'(2)/s^2) output matrix\n",
    "    % X: (C L(1) L(2)) x (K T'(1) T'(2)/s^2) input matrix\n",
    "    % W: D x (C L(1) L(2)) matrix \n",
    "    \"\"\"\n",
    "\n",
    "    batch_size, channels, height, width = inp.shape\n",
    "    out_size, _, kernel_height, kernel_width = w.shape\n",
    "    \n",
    "    W = []\n",
    "    X = []\n",
    "\n",
    "    if padding == 'same':\n",
    "        L1 = math.floor((L-1)/2)\n",
    "        L2 = math.ceil((L-1)/2)\n",
    "    elif padding == 'full':\n",
    "        L1 = [0 0]\n",
    "        L2 = [0 0]\n",
    "    else:\n",
    "        print ('padding undefined')\n",
    "\n",
    "    for c in range(channels):\n",
    "        W = [W reshape(h(:,c,:,:),[D L(1)*L(2)])];\n",
    "        XX = [];\n",
    "        for k = 1:K\n",
    "             for t2 = L(2)-L1(2):s:T(2)+L2(2)\n",
    "    %            for t1 = L(1)-L1(1):T(1)+L2(1)\n",
    "                    %xxt = [];\n",
    "                    XXT = [];\n",
    "                    for tt2 = t2:-1:t2-L(2)+1\n",
    "                        if tt2 > 0 & tt2 <= T(2)\n",
    "                            XXT = [XXT;toeplitz([x(c,L(1)-L1(1):-1:1,tt2,k) zeros(1,L1(1))],[x(c,L(1)-L1(1):end,tt2,k) zeros(1,L2(1))])];\n",
    "                        else\n",
    "                            XXT = [XXT;zeros(L(1),T(1))];\n",
    "                        end\n",
    "                        %xxt = [xxt x(c,t1:-1:t1-L(1)+1,tt2,k)];\n",
    "                    end\n",
    "                    %XX = [XX xxt(:)];\n",
    "                    XX = [XX XXT(:,1:s:end)];\n",
    "    %            end\n",
    "             end\n",
    "\n",
    "            %XXT = toeplitz([x(c,L-L1:-1:1,k) zeros(1,L1)],[x(c,L-L1:end,k) zeros(1,L2)]);\n",
    "            %XX = [XX XXT(:,1:s:end)];\n",
    "        end\n",
    "        X = [X;XX];\n",
    "    end\n",
    "\n",
    "    %size(X)\n",
    "    %size(W)\n",
    "    Y = W*X;\n",
    "\n",
    "    end"
>>>>>>> 9f246edb5948743bdc75fc1efea83f707fcd5e56
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fdb52689-92d4-450e-8e51-ba0647a3404d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.271357924035143e-28\n"
     ]
    }
   ],
   "source": [
    "# k = np.random.randn(8, 3, 3, 3)\n",
    "# i = np.random.randn(3, 10, 12)\n",
    "\n",
    "# T = toeplitz_mult_ch(k, i.shape)\n",
    "# out = T.dot(i.flatten()).reshape((1, 8, 8, 10))\n",
    "\n",
    "# check correctness of convolution via toeplitz matrix\n",
    "print(np.sum((out - F.conv2d(torch.tensor(i).view(1,3,10,12), torch.tensor(k)).numpy())**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9e6a6cbe-2c3f-4313-9a9f-745b8b8052c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 48, 841]) torch.Size([48, 2])\n",
      "torch.Size([32, 2, 841])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5.1425e-08)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolution is equivalent with Unfold + Matrix Multiplication + Fold (or view to output shape)\n",
    "inp = torch.randn(32, 3, 32, 32)\n",
    "w = torch.randn(2, 3, 4, 4)\n",
    "inp_unf = torch.nn.functional.unfold(inp, (4, 4), stride=1, padding=0)\n",
    "print (inp_unf.shape, w.view(w.size(0), -1).t().shape)\n",
    "out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "print (out_unf.shape)\n",
    "out = out_unf.view(32, 2, 29, 29)\n",
    "torch.sum((F.conv2d(inp, w, stride=1, padding=0) - out)**2)\n",
    "# tensor(1.9073e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "82b55289-0201-4bea-b58e-81227adb7a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 29, 29)\n",
      "(1682,)\n"
     ]
    }
   ],
   "source": [
    "T = toeplitz_mult_ch(w, inp.squeeze().shape)\n",
    "out_toe = T.dot(inp.flatten())\n",
    "print (out_toe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "deccd2f6-b265-46c2-b7c6-2575d116cfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 48]) torch.Size([32, 2, 841]) torch.Size([32, 48, 841])\n"
     ]
    }
   ],
   "source": [
    "z = out_unf \n",
    "fc = torch.sum(z**2, axis=0)\n",
    "fc = torch.mean(fc)\n",
    "aW_unf = torch.zeros(w.view(w.size(0), -1).shape)\n",
    "\n",
    "if fc > 0:\n",
    "    tW = aW_unf\n",
    "    for k in range(1):\n",
    "        tW += 2 * (z[k, :] @ inp_unf[k, :].T)\n",
    "    aW_unf = -fc * tW / torch.linalg.norm(tW)**2\n",
    "    \n",
    "print (aW_unf.shape, out_unf.shape, inp_unf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "45cd9629-5676-4b6f-8f89-269b5bd53e93",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size, expected tensor [1682] and src [3072] to have the same number of elements, but got 1682 and 3072 elements respectively",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [152], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m tW \u001b[38;5;241m=\u001b[39m aW_toe\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     tW \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[43mz\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m)\n\u001b[1;32m     10\u001b[0m aW_toe \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mfc \u001b[38;5;241m*\u001b[39m tW \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(tW)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size, expected tensor [1682] and src [3072] to have the same number of elements, but got 1682 and 3072 elements respectively"
     ]
    }
   ],
   "source": [
    "z = torch.from_numpy(out_toe).view(1, -1).float()\n",
    "fc = torch.sum(z**2, axis=0)\n",
    "fc = torch.mean(fc)\n",
    "aW_toe = torch.zeros(T.shape)\n",
    "\n",
    "if fc > 0:\n",
    "    tW = aW_toe\n",
    "    for k in range(1):\n",
    "        tW += 2 * (z[k, :] @ inp[k, :].flatten().T)\n",
    "    aW_toe = -fc * tW / torch.linalg.norm(tW)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c2ad0d88-193e-42c2-b187-bc7072c7bbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2, 29, 29), torch.Size([1, 3, 32, 32]))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_toe.reshape(1, 2, 29, 29).shape, inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7558643-48c6-4b58-ba5c-e9ef8728f3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
